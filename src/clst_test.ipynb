{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-22T14:23:51.556398Z",
     "start_time": "2025-06-22T14:23:42.012692Z"
    }
   },
   "source": [
    "# %% [markdown]\n",
    "# # 분류 모델 추론 스크립트 (Notebook Edition)\n",
    "# * 로컬 `roberta/` 폴더에 fine-tuning 된 모델이 있다고 가정\n",
    "# * 테스트 데이터: `./data/cls_test.json`\n",
    "# * 결과는 `cls_output.json`으로 저장\n",
    "\n",
    "# %% Imports & 환경설정\n",
    "import os, json, torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM, pipeline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"✔ Using device:\", device)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:26:03.420048Z",
     "start_time": "2025-06-22T14:26:03.413888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_dir = os.getcwd()  # Jupyter에서는 __file__ 대신\n",
    "roberta_path = \"./roberta\"\n",
    "kogpt2_path = os.path.join(base_dir, \"..\", \"kogpt2-finetuned\")\n",
    "\n",
    "label_map = {\n",
    "    0: \"졸업요건\",\n",
    "    1: \"학교 공지사항\",\n",
    "    2: \"학사일정\",\n",
    "    3: \"식단 안내\",\n",
    "    4: \"통학/셔틀 버스\"\n",
    "}"
   ],
   "id": "a5c369d772f0d8c9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:31:13.929166Z",
     "start_time": "2025-06-22T14:30:55.312874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_path)\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(roberta_path).to(device).eval()\n",
    "\n",
    "kogpt2_tokenizer = AutoTokenizer.from_pretrained(kogpt2_path)\n",
    "kogpt2_model = AutoModelForCausalLM.from_pretrained(kogpt2_path).to(device)\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=kogpt2_model,\n",
    "    tokenizer=kogpt2_tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n"
   ],
   "id": "d6a3411f94082bd2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:33:31.236412Z",
     "start_time": "2025-06-22T14:33:31.227308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_path = os.path.join(base_dir, \"..\", \"data\", \"cls_test.json\")\n",
    "output_path = os.path.join(base_dir, \"..\", \"outputs\", \"output.json\")\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "questions = [entry.get(\"question\", \"\").strip() for entry in data if entry.get(\"question\", \"\").strip()]\n",
    "print(f\"✔ {len(questions)}개의 질문이 로드되었습니다.\")"
   ],
   "id": "8f8c721ffa10e17d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 1000개의 질문이 로드되었습니다.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:44:54.293891Z",
     "start_time": "2025-06-22T14:33:39.297631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 분류\n",
    "inputs = roberta_tokenizer(questions, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "with torch.no_grad():\n",
    "    logits = roberta_model(**inputs).logits\n",
    "    pred_ids = logits.argmax(dim=-1).cpu().tolist()\n",
    "topics = [label_map.get(pred_id, \"기타\") for pred_id in pred_ids]\n",
    "\n",
    "# 프롬프트\n",
    "prompts = [f\"[TOPIC] {topic} [USER] {question} [SEP] [BOT]\" for topic, question in zip(topics, questions)]\n",
    "\n",
    "# 답변 생성\n",
    "generated_outputs = generator(\n",
    "    prompts,\n",
    "    max_new_tokens=50,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,\n",
    "    pad_token_id=kogpt2_tokenizer.eos_token_id\n",
    ")\n"
   ],
   "id": "3d4d1aad0e902256",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:47:02.708837Z",
     "start_time": "2025-06-22T14:47:02.689809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = []\n",
    "for question, prompt, topic, gen in zip(questions, prompts, topics, generated_outputs):\n",
    "    generated_text = gen[0][\"generated_text\"]\n",
    "    answer = generated_text.replace(prompt, \"\").strip()\n",
    "\n",
    "    if not answer or len(answer) < 5:\n",
    "        answer = \"죄송합니다. 답변을 생성할 수 없습니다.\"\n",
    "\n",
    "    results.append({\n",
    "        \"question\": question,\n",
    "        \"topic\": topic,\n",
    "        \"answer\": answer\n",
    "    })\n",
    "\n",
    "# 저장\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ 총 {len(results)}건 처리 완료 → {output_path}\")\n"
   ],
   "id": "2656bdafc7377385",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 총 1000건 처리 완료 → D:\\lastproject\\Termproject_{9조}\\src\\..\\outputs\\output.json\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:48:08.957144Z",
     "start_time": "2025-06-22T14:48:08.944245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# %% 결과 저장\n",
    "out_path = os.path.join(base_dir, \"cls_output.json\")\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"📄 Saved predictions to:\", out_path)"
   ],
   "id": "e516a294a2a346e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Saved predictions to: D:\\lastproject\\Termproject_{9조}\\src\\cls_output.json\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
