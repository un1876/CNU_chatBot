{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-22T14:23:51.556398Z",
     "start_time": "2025-06-22T14:23:42.012692Z"
    }
   },
   "source": [
    "# %% [markdown]\n",
    "# # ë¶„ë¥˜ ëª¨ë¸ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ (Notebook Edition)\n",
    "# * ë¡œì»¬ `roberta/` í´ë”ì— fine-tuning ëœ ëª¨ë¸ì´ ìˆë‹¤ê³  ê°€ì •\n",
    "# * í…ŒìŠ¤íŠ¸ ë°ì´í„°: `./data/cls_test.json`\n",
    "# * ê²°ê³¼ëŠ” `cls_output.json`ìœ¼ë¡œ ì €ì¥\n",
    "\n",
    "# %% Imports & í™˜ê²½ì„¤ì •\n",
    "import os, json, torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM, pipeline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"âœ” Using device:\", device)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” Using device: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:26:03.420048Z",
     "start_time": "2025-06-22T14:26:03.413888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "base_dir = os.getcwd()  # Jupyterì—ì„œëŠ” __file__ ëŒ€ì‹ \n",
    "roberta_path = \"./roberta\"\n",
    "kogpt2_path = os.path.join(base_dir, \"..\", \"kogpt2-finetuned\")\n",
    "\n",
    "label_map = {\n",
    "    0: \"ì¡¸ì—…ìš”ê±´\",\n",
    "    1: \"í•™êµ ê³µì§€ì‚¬í•­\",\n",
    "    2: \"í•™ì‚¬ì¼ì •\",\n",
    "    3: \"ì‹ë‹¨ ì•ˆë‚´\",\n",
    "    4: \"í†µí•™/ì…”í‹€ ë²„ìŠ¤\"\n",
    "}"
   ],
   "id": "a5c369d772f0d8c9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:31:13.929166Z",
     "start_time": "2025-06-22T14:30:55.312874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "roberta_tokenizer = AutoTokenizer.from_pretrained(roberta_path)\n",
    "roberta_model = AutoModelForSequenceClassification.from_pretrained(roberta_path).to(device).eval()\n",
    "\n",
    "kogpt2_tokenizer = AutoTokenizer.from_pretrained(kogpt2_path)\n",
    "kogpt2_model = AutoModelForCausalLM.from_pretrained(kogpt2_path).to(device)\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=kogpt2_model,\n",
    "    tokenizer=kogpt2_tokenizer,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n"
   ],
   "id": "d6a3411f94082bd2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:33:31.236412Z",
     "start_time": "2025-06-22T14:33:31.227308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_path = os.path.join(base_dir, \"..\", \"data\", \"cls_test.json\")\n",
    "output_path = os.path.join(base_dir, \"..\", \"outputs\", \"output.json\")\n",
    "\n",
    "with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "questions = [entry.get(\"question\", \"\").strip() for entry in data if entry.get(\"question\", \"\").strip()]\n",
    "print(f\"âœ” {len(questions)}ê°œì˜ ì§ˆë¬¸ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ],
   "id": "8f8c721ffa10e17d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” 1000ê°œì˜ ì§ˆë¬¸ì´ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:44:54.293891Z",
     "start_time": "2025-06-22T14:33:39.297631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ë¶„ë¥˜\n",
    "inputs = roberta_tokenizer(questions, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "with torch.no_grad():\n",
    "    logits = roberta_model(**inputs).logits\n",
    "    pred_ids = logits.argmax(dim=-1).cpu().tolist()\n",
    "topics = [label_map.get(pred_id, \"ê¸°íƒ€\") for pred_id in pred_ids]\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸\n",
    "prompts = [f\"[TOPIC] {topic} [USER] {question} [SEP] [BOT]\" for topic, question in zip(topics, questions)]\n",
    "\n",
    "# ë‹µë³€ ìƒì„±\n",
    "generated_outputs = generator(\n",
    "    prompts,\n",
    "    max_new_tokens=50,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,\n",
    "    pad_token_id=kogpt2_tokenizer.eos_token_id\n",
    ")\n"
   ],
   "id": "3d4d1aad0e902256",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:47:02.708837Z",
     "start_time": "2025-06-22T14:47:02.689809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results = []\n",
    "for question, prompt, topic, gen in zip(questions, prompts, topics, generated_outputs):\n",
    "    generated_text = gen[0][\"generated_text\"]\n",
    "    answer = generated_text.replace(prompt, \"\").strip()\n",
    "\n",
    "    if not answer or len(answer) < 5:\n",
    "        answer = \"ì£„ì†¡í•©ë‹ˆë‹¤. ë‹µë³€ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    results.append({\n",
    "        \"question\": question,\n",
    "        \"topic\": topic,\n",
    "        \"answer\": answer\n",
    "    })\n",
    "\n",
    "# ì €ì¥\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ… ì´ {len(results)}ê±´ ì²˜ë¦¬ ì™„ë£Œ â†’ {output_path}\")\n"
   ],
   "id": "2656bdafc7377385",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì´ 1000ê±´ ì²˜ë¦¬ ì™„ë£Œ â†’ D:\\lastproject\\Termproject_{9ì¡°}\\src\\..\\outputs\\output.json\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-22T14:48:08.957144Z",
     "start_time": "2025-06-22T14:48:08.944245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# %% ê²°ê³¼ ì €ì¥\n",
    "out_path = os.path.join(base_dir, \"cls_output.json\")\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"ğŸ“„ Saved predictions to:\", out_path)"
   ],
   "id": "e516a294a2a346e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“„ Saved predictions to: D:\\lastproject\\Termproject_{9ì¡°}\\src\\cls_output.json\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
